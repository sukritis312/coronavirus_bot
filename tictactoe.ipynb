{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMzKY6FmTn6RHSGIbhAnw1T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sukritis312/coronavirus_bot/blob/main/tictactoe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDDdSgXTUSMV"
      },
      "outputs": [],
      "source": [
        "!pip install gym"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/playing-tictactoe-with-reinforcement-learning-and-openai-gym/gym-tictactoe.zip"
      ],
      "metadata": {
        "id": "4DL5vcRwVJqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o gym-tictactoe.zip"
      ],
      "metadata": {
        "id": "QqGvUXNiValo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e gym-tictactoe"
      ],
      "metadata": {
        "id": "mU5npgdFVvJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gym==0.19.0"
      ],
      "metadata": {
        "id": "tTzOjOzJcZ1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "![Policy Table](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/playing-tictactoe-with-reinforcement-learning-and-openai-gym/images/policy.png)\n"
      ],
      "metadata": {
        "id": "XhQ_2M1yeEMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import random\n",
        "import gym_tictactoe\n",
        "#work with open-ai gym environment\n",
        "env = gym.make(\"TicTacToe-v0\")\n",
        "#working with tictactoe evironment\n",
        "env.state\n",
        "env.hash()\n",
        "new_state, reward, done, info = env.step(0, \"X\")\n",
        "# variable to keep track of if the game is over\n",
        "done = False\n",
        "# Good practice to reset environment before you play a game to clear any old game\n",
        "env.reset()\n",
        "# Want to keep playing untill game is over\n",
        "while not done:\n",
        "    # Make a random action from the list of available actions for X\n",
        "    new_state, reward, done, info = env.step(random.choice(env.available_actions()), \"X\")\n",
        "    # Print state\n",
        "    print(env.hash())\n",
        "    \n",
        "    # If the game is done on X action we dont want O to make an action\n",
        "    if not done:\n",
        "        # Make a random action from the list of available actions for O\n",
        "        new_state, reward, done, info = env.step(random.choice(env.available_actions()), \"O\")\n",
        "        # Print state\n",
        "        print(env.hash())"
      ],
      "metadata": {
        "id": "H1_VvIPNWMKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "    \n",
        "    def __init__(self, env, player=\"X\", alpha=.4, gamma=.9):\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.env = env\n",
        "        self.player = player\n",
        "        self.player_number = 0 if player == \"X\" else 1\n",
        "        self.V = {}"
      ],
      "metadata": {
        "id": "R4fYYh4To5K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent(Agent):\n",
        "\n",
        "    def select_action(self, epsilon=.1):\n",
        "        if (random.random() < epsilon):\n",
        "            action = random.choice(self.env.available_actions())\n",
        "        else:\n",
        "            q_values = [] \n",
        "            for state in self.env.available_states(self.player):\n",
        "                q_values.append(self.gamma*self.V[state[0]] + state[1][self.player_number])\n",
        "            max_value = max(q_values)\n",
        "            max_indexs = [i for i, j in enumerate(q_values) if j == max_value]\n",
        "            action = self.env.available_actions()[random.choice(max_indexs)]\n",
        "        return action"
      ],
      "metadata": {
        "id": "Bw0CtKEbqMqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent(Agent):\n",
        "    \n",
        "    def add_states(self):\n",
        "        if (self.env.hash() not in self.V):\n",
        "            self.V[self.env.hash()] = 0\n",
        "        for state in self.env.available_states(\"X\"):\n",
        "            if (state[0] not in self.V):\n",
        "                self.V[state[0]] = 0\n",
        "        for state in self.env.available_states(\"O\"):\n",
        "            if (state[0] not in self.V):\n",
        "                self.V[state[0]] = 0"
      ],
      "metadata": {
        "id": "v91Gw_Q4qXCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent(Agent):\n",
        "    \n",
        "    def update_state_values(self, new_state, old_state, reward):\n",
        "        self.V[old_state] = self.V[old_state] + self.alpha*(reward + self.gamma*self.V[new_state] - self.V[old_state])"
      ],
      "metadata": {
        "id": "UUB6MWmsq9pF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model\n",
        "# number of games (episodes)\n",
        "def train(episodes):\n",
        "    # create our agents\n",
        "    agent_x = Agent(env, \"X\")\n",
        "    agent_o = Agent(env, \"O\")\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "            \n",
        "            # X agents turn\n",
        "\n",
        "            # adds states for both agents\n",
        "            agent_x.add_states()\n",
        "            agent_o.add_states()\n",
        "            \n",
        "            # records the state we are in before action\n",
        "            old_state = env.hash()\n",
        "            # get an action using policy\n",
        "            action = agent_x.select_action()\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(action, agent_x.player)\n",
        "            \n",
        "            # update state values for both agents\n",
        "            agent_x.update_state_values(new_state, old_state, reward[agent_x.player_number])\n",
        "            agent_o.update_state_values(new_state, old_state, reward[agent_o.player_number])\n",
        "            \n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if not done:\n",
        "                \n",
        "                # O agents turn\n",
        "                \n",
        "                # adds states for both agents\n",
        "                agent_x.add_states()\n",
        "                agent_o.add_states()\n",
        "\n",
        "                # records the state we are in before action\n",
        "                old_state = env.hash()\n",
        "                # get an action using policy\n",
        "                action = agent_o.select_action()\n",
        "                # performs an action\n",
        "                new_state, reward, done, _ = env.step(action, agent_o.player)\n",
        "\n",
        "                # update state values for both agents\n",
        "                agent_x.update_state_values(new_state, old_state, reward[agent_x.player_number])\n",
        "                agent_o.update_state_values(new_state, old_state, reward[agent_o.player_number])\n",
        "                \n",
        "    return agent_x, agent_o"
      ],
      "metadata": {
        "id": "PZhiQ6JmrCoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "agent_x, agent_o = train(110000)"
      ],
      "metadata": {
        "id": "f9C7eo4SrgtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def test_x(episodes):\n",
        "    # counters to keep track of results\n",
        "    win = 0\n",
        "    tie = 0\n",
        "    loss = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "            \n",
        "            # adds states for X only because we are acting randomly and not updating state values for O\n",
        "            agent_x.add_states()\n",
        "            \n",
        "            # always get the best action\n",
        "            x_action = agent_x.select_action(epsilon=0)\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, agent_x.player)\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "                \n",
        "                # O agents turn\n",
        "                \n",
        "                # adds states for X only because we are acting randomly and not updating state values for O\n",
        "                agent_x.add_states()\n",
        "                \n",
        "                # O always makes a random action from the available actions\n",
        "                o_action = random.choice(env.available_actions())\n",
        "                new_state, reward, done, _ = env.step(o_action, \"O\")\n",
        "                \n",
        "        # record results when game is done\n",
        "        if (reward == (10, -10)):\n",
        "            win+=1\n",
        "        elif (reward == (-10, 10)):\n",
        "            loss+=1\n",
        "        elif (reward == (0, 0)):\n",
        "            tie+=1\n",
        "    return win, loss, tie\n",
        "episodes = 10000\n",
        "\n",
        "win, loss, tie = test_x(episodes)\n",
        "\n",
        "print(\"Win:\", win, \"Tie:\", tie, \"Loss:\", loss)\n",
        "print(\"Win Rate:\", win/episodes*100, \"Tie Rate:\", tie/episodes*100, \"Loss Rate:\", loss/episodes*100)"
      ],
      "metadata": {
        "id": "nRFyEV6RsK93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def test_o(episodes):\n",
        "    # counters to keep track of results\n",
        "    win = 0\n",
        "    tie = 0\n",
        "    loss = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "            \n",
        "            # adds states for O only because we are acting randomly and not updating state values for X\n",
        "            agent_o.add_states()\n",
        "            \n",
        "            # X always makes a random action from the available actions\n",
        "            x_action = random.choice(env.available_actions())\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, \"X\")\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "                \n",
        "                # O agents turn\n",
        "                \n",
        "                # adds states for O only because we are acting randomly and not updating state values for X\n",
        "                agent_o.add_states()\n",
        "                \n",
        "                # always get the best action\n",
        "                o_action = agent_o.select_action(epsilon=0)\n",
        "                new_state, reward, done, _ = env.step(o_action, agent_o.player)\n",
        "                \n",
        "        # record results when game is done\n",
        "        if (reward == (-10, 10)):\n",
        "            win+=1\n",
        "        elif (reward == (10, -10)):\n",
        "            loss+=1\n",
        "        elif (reward == (0, 0)):\n",
        "            tie+=1\n",
        "    return win, loss, tie"
      ],
      "metadata": {
        "id": "FkSoycRguRNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def test_o(episodes):\n",
        "    # counters to keep track of results\n",
        "    win = 0\n",
        "    tie = 0\n",
        "    loss = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "            \n",
        "            # adds states for O only because we are acting randomly and not updating state values for X\n",
        "            agent_o.add_states()\n",
        "            \n",
        "            # X always makes a random action from the available actions\n",
        "            x_action = random.choice(env.available_actions())\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, \"X\")\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "                \n",
        "                # O agents turn\n",
        "                \n",
        "                # adds states for O only because we are acting randomly and not updating state values for X\n",
        "                agent_o.add_states()\n",
        "                \n",
        "                # always get the best action\n",
        "                o_action = agent_o.select_action(epsilon=0)\n",
        "                new_state, reward, done, _ = env.step(o_action, agent_o.player)\n",
        "                \n",
        "        # record results when game is done\n",
        "        if (reward == (-10, 10)):\n",
        "            win+=1\n",
        "        elif (reward == (10, -10)):\n",
        "            loss+=1\n",
        "        elif (reward == (0, 0)):\n",
        "            tie+=1\n",
        "    return win, loss, tie"
      ],
      "metadata": {
        "id": "GN5bHcuTvB-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 10000\n",
        "\n",
        "win, loss, tie = test_o(episodes)\n",
        "\n",
        "print(\"Win:\", win, \"Tie:\", tie, \"Loss:\", loss)\n",
        "print(\"Win Rate:\", win/episodes*100, \"Tie Rate:\", tie/episodes*100, \"Loss Rate:\", loss/episodes*100)"
      ],
      "metadata": {
        "id": "VoiOzZoHva0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def test(episodes):\n",
        "    # counters to keep track of results\n",
        "    x_win = 0\n",
        "    o_win = 0\n",
        "    tie = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "            \n",
        "            # adds states for both agents because we are using select_action on both\n",
        "            agent_x.add_states()\n",
        "            agent_o.add_states()\n",
        "            \n",
        "            # always get the best action\n",
        "            x_action = agent_x.select_action(epsilon=0)\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, \"X\")\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "                \n",
        "                # O agents turn\n",
        "                \n",
        "                # adds states for both agents because we are using select_action on both\n",
        "                agent_x.add_states()\n",
        "                agent_o.add_states()\n",
        "                \n",
        "                # always get the best action\n",
        "                o_action = agent_o.select_action(epsilon=0)\n",
        "                new_state, reward, done, _ = env.step(o_action, \"O\")\n",
        "                \n",
        "        # record results when game is done\n",
        "        if (reward == (-10, 10)):\n",
        "            o_win+=1\n",
        "        elif (reward == (10, -10)):\n",
        "            x_win+=1\n",
        "        elif (reward == (0, 0)):\n",
        "            tie+=1\n",
        "    return x_win, o_win, tie"
      ],
      "metadata": {
        "id": "V8iyz8O8wKpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 10000\n",
        "\n",
        "x_win, o_win, tie = test(episodes)\n",
        "\n",
        "print(\"X Win:\", x_win, \"Tie:\", tie, \"O Win:\", o_win)\n",
        "print(\"X Win Rate:\", x_win/episodes*100, \"Tie Rate:\", tie/episodes*100, \"O Win Rate:\", o_win/episodes*100)"
      ],
      "metadata": {
        "id": "J6J9qWKnwSD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#play against agent\n",
        "# number of games (episodess)\n",
        "def play_as_x(episodes=1):\n",
        "    # counters to keep track of results\n",
        "    x_win = 0\n",
        "    o_win = 0\n",
        "    tie = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "            \n",
        "            # print the environment before you go\n",
        "            env.render()\n",
        "            # print available actions\n",
        "            print(env.available_actions())\n",
        "            \n",
        "            # adds states for O only because we are controlling X\n",
        "            agent_o.add_states()\n",
        "            \n",
        "            # get user input\n",
        "            x_action = int(input())\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, \"X\")\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "                \n",
        "                # O agents turn\n",
        "                \n",
        "                # adds states for O only because we are controlling X \n",
        "                agent_o.add_states()\n",
        "                \n",
        "                # always get the best action\n",
        "                o_action = agent_o.select_action(epsilon=0)\n",
        "                new_state, reward, done, _ = env.step(o_action, \"O\")\n",
        "        \n",
        "        env.render()\n",
        "        # record results when game is done\n",
        "        if (reward == (-10, 10)):\n",
        "            print(\"You Lose\")\n",
        "        elif (reward == (10, -10)):\n",
        "            print(\"You Win\")\n",
        "        elif (reward == (0, 0)):\n",
        "            print(\"Tie\")"
      ],
      "metadata": {
        "id": "DijmQMnRwkyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_as_x()"
      ],
      "metadata": {
        "id": "kJYaLGObwrJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of games (episodes)\n",
        "def play_as_o(episodes=1):\n",
        "    # counters to keep track of results\n",
        "    x_win = 0\n",
        "    o_win = 0\n",
        "    tie = 0\n",
        "    # loops for a certain number of games (episodes)\n",
        "    for episode in range(episodes):\n",
        "        # stops while loop when game is done\n",
        "        done = False\n",
        "        # resets environment when game is done\n",
        "        env.reset()\n",
        "        while not done:\n",
        "            \n",
        "            # adds states for X only because we are controlling O\n",
        "            agent_x.add_states()\n",
        "            \n",
        "            # always get the best action\n",
        "            x_action = agent_x.select_action(epsilon=0)\n",
        "            # performs an action\n",
        "            new_state, reward, done, _ = env.step(x_action, \"X\")\n",
        "\n",
        "            # if the game ends on X move, we don't want to make an O move\n",
        "            if (not done):\n",
        "                \n",
        "                # O agents turn\n",
        "                \n",
        "                # print the environment before you go\n",
        "                env.render()\n",
        "                # print available actions\n",
        "                print(env.available_actions())\n",
        "                \n",
        "                # adds states for X only because we are controlling O\n",
        "                agent_x.add_states()\n",
        "                \n",
        "                # get user input\n",
        "                o_action = int(input())\n",
        "                new_state, reward, done, _ = env.step(o_action, \"O\")\n",
        "        \n",
        "        env.render()\n",
        "        # record results when game is done\n",
        "        if (reward == (-10, 10)):\n",
        "            print(\"You Win\")\n",
        "        elif (reward == (10, -10)):\n",
        "            print(\"You Lose\")\n",
        "        elif (reward == (0, 0)):\n",
        "            print(\"Tie\")"
      ],
      "metadata": {
        "id": "HLk-nO6XxCMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_as_o()"
      ],
      "metadata": {
        "id": "nwNP1sBHxIAf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}